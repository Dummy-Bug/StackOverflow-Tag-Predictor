{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SO_tag_predictor_Modeling_self.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Models "
      ],
      "metadata": {
        "id": "QsaOy8cyxru0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install scikit-multilearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPYjWps1hwAW",
        "outputId": "91d6757a-7587-40d9-d266-01fdeabde750"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-multilearn in /usr/local/lib/python3.7/dist-packages (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Z3V8jMf_goSg"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "import os\n",
        "from sqlalchemy import create_engine # database connection\n",
        "import datetime as dt\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from skmultilearn.adapt import mlknn\n",
        "from skmultilearn.problem_transform import ClassifierChain\n",
        "from skmultilearn.problem_transform import BinaryRelevance\n",
        "from skmultilearn.problem_transform import LabelPowerset\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# http://www.sqlitetutorial.net/sqlite-python/create-tables/\n",
        "\n",
        "def create_connection(db_file):\n",
        "\n",
        "    \"\"\" create a database connection to the SQLite database\n",
        "        specified by db_file\n",
        "    :param db_file: database file\n",
        "    :return: Connection object or None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        conn = sqlite3.connect(db_file) # connecting to the database \n",
        "        return conn\n",
        "   \n",
        "    except Error as e:\n",
        "        print(e)\n",
        " \n",
        "    return None\n",
        "\n",
        "def create_table(conn, create_table_sql):\n",
        "\n",
        "    \"\"\" create a table from the create_table_sql statement\n",
        "    :param conn: Connection object\n",
        "    :param create_table_sql: a CREATE TABLE statement\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    try:\n",
        "        c = conn.cursor()\n",
        "        c.execute(create_table_sql)\n",
        "\n",
        "    except Error as e:\n",
        "        print(e)\n",
        "        \n",
        "def checkTableExists(dbcon):\n",
        "\n",
        "    cursr = dbcon.cursor()\n",
        "    str = \"select name from sqlite_master where type = 'table'\"\n",
        "    table_names = cursr.execute(str)\n",
        "    print(\"Tables in the databse:\")\n",
        "    tables = table_names.fetchall() \n",
        "    print(tables[0][0])\n",
        "    return(len(tables))\n",
        "\n",
        "def create_database_table(database, query):\n",
        "    conn = create_connection(database)\n",
        "    if conn is not None:\n",
        "        create_table(conn, query)\n",
        "        checkTableExists(conn)\n",
        "    else:\n",
        "        print(\"Error! cannot create the database connection.\")\n",
        "    conn.close()\n",
        "\n",
        "sql_create_table = \"\"\"CREATE TABLE IF NOT EXISTS QuestionsProcessed (question text NOT NULL, code text, tags text, words_pre integer, words_post integer, is_code integer);\"\"\"\n",
        "create_database_table(\"Processed.db\", sql_create_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu7cOMTHjGt8",
        "outputId": "a0b7d0ff-fd14-4630-ada0-5d68dcda7aa6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tables in the databse:\n",
            "QuestionsProcessed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "\n",
        "database_path = '/content/drive/MyDrive/Case Studies/Stack Overflow Tag Predictor /data/Titlemoreweight.db'\n",
        "\n",
        "if os.path.isfile(database_path):\n",
        "    conn_r = create_connection(database_path) # create a connection to the database\n",
        "\n",
        "    if conn_r is not None: # if connection is created successfully then read questions and Tags from the Table QuestionProcessed\n",
        "        preprocessed_data = pd.read_sql_query(\"\"\"SELECT question, Tags FROM QuestionsProcessed\"\"\", conn_r)\n",
        "\n",
        "conn_r.commit()\n",
        "conn_r.close()"
      ],
      "metadata": {
        "id": "WHVqP-BrhYaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f06fddd-a4dd-4e9c-b133-b41ad3a0f679"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.99 s, sys: 3.13 s, total: 6.11 s\n",
            "Wall time: 1min 19s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_data = preprocessed_data.head(100000)"
      ],
      "metadata": {
        "id": "KYvn9pmVivxo"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessed_data = preprocessed_data.head(101)"
      ],
      "metadata": {
        "id": "D7YmNJ8YZjJe"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"number of data points in sample :\", preprocessed_data.shape[0])\n",
        "print(\"number of dimensions :\", preprocessed_data.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9sYqGI2j9iU",
        "outputId": "fd0f29e9-32a0-4ee2-b7fc-514ab0466d0c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of data points in sample : 100000\n",
            "number of dimensions : 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multi-Label Classification**\n",
        "\n",
        "* since we already know how to solve Binary Classification and Multi-class problem using LR,SVM,DT etc\n",
        "so if we can manage to convert Multi-label problem into Binary classification problem then we can leverage all the techniques to solve this problem too \n",
        "\n",
        "\n",
        "please go through the following blog for better understanding of the concept \n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2017/08/introduction-to-multi-label-classification/ \n",
        "\n",
        "Here we won't be using Binary Relevence[OneVSrest] approach as we have around 30k unique tags(labels) instead of 4.As we might end up doing 30k classifications which can take lot of time.\n",
        "\n",
        "* Thus sklmultilearn is very useful if we have smaller dataset.\n",
        "\n",
        "Hence we will use second approach called classifier chains.well even in here we have to do 30k classifications but this helps whenever is one label is related to another.e.g c++ and pointers are highly related to one another so this methods more useful than the one mentioned above."
      ],
      "metadata": {
        "id": "2UYujNWaorYc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting string Tags to multilable output variables** "
      ],
      "metadata": {
        "id": "u-7othirlpZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer   = CountVectorizer(tokenizer = lambda x: x.split(), binary = 'true')\n",
        "multilabel_y = vectorizer.fit_transform(preprocessed_data['tags'])\n",
        "\n",
        "# If you set binary = True then CountVectorizer no longer uses the counts of terms/tokens. If a token is present in a document,\n",
        "# it is 1, if absent it is 0 regardless of its frequency of occurrence. So you will be dealing with just binary values. \n",
        "# By default, binary=False "
      ],
      "metadata": {
        "id": "DruEanz6kI4_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#'get_feature_name()' gives us the vocabulary.\n",
        "\n",
        "tags = vectorizer.get_feature_names()\n",
        "print(multilabel_y.shape)\n",
        "print(\"Some of the tags we have after Tokenization and applying Vectorizer are-:\\n\", tags[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3dEf8eulynw",
        "outputId": "a95ad632-fc0d-45bb-f78b-9734747f0c49"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 16321)\n",
            "Some of the tags we have after Tokenization and applying Vectorizer are-:\n",
            " ['.aspxauth', '.bash-profile', '.class-file', '.cs-file', '.doc', '.each', '.emf', '.exe', '.htaccess', '.htpasswd']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> 4.1 Converting tags for multilabel problems </h2>"
      ],
      "metadata": {
        "id": "8yED4c-dxpJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table>\n",
        "<tr>\n",
        "<th>X</th><th>y1</th><th>y2</th><th>y3</th><th>y4</th>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>x1</td><td>0</td><td>1</td><td>1</td><td>0</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>x1</td><td>1</td><td>0</td><td>0</td><td>0</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>x1</td><td>0</td><td>1</td><td>0</td><td>0</td>\n",
        "</tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "ufl2InzaxyFr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Since we already know training 30k Labels is very time consuming so let's see if we can decrease the number of tags without loosing much of the information\n",
        "\n",
        "* so we want only the subset of all the tags . let's say we have a datapoint \n",
        "x1 with labels as t1,t2,t3 and datapoint x2 with labels as t3,t4,t5 . say our subset c' has labels only {t1,t2}. then our x2 vector would be [1,1]{partial coverage}(as only t1 and t2 are present in subset t3 is missing)\n",
        "On other hand our x2 will have Null vector or phie set as there is not any tag present in subset.Hence we will remove such datapoints\n",
        "\n",
        "* Thus we can take the top tags by frequency ,as these tags would be present in most of the questions ,so if we put these most frequent tags in my subset c' I will able to generate non Null datapoints partially.Hence there would be less datapoints with NUll value."
      ],
      "metadata": {
        "id": "9PSYTAENt-iV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will sample the number of tags instead considering all of them (due to limitation of computing power) "
      ],
      "metadata": {
        "id": "IzPpUiigx3wm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* https://stackoverflow.com/questions/40200070/what-does-axis-0-do-in-numpys-sum-function"
      ],
      "metadata": {
        "id": "YedfS9RDVPWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tags_to_choose(n): # take only 10 rows from preprocessed data to undterstand this code easily.\n",
        "\n",
        "    # print(type(multilabel_y.sum(axis = 0) ) # returns numpy matrix , so using .tolist()\n",
        "\n",
        "    t = multilabel_y.sum(axis = 0).tolist()[0] # summ all the columns(row-wise), will return list(list) for every column hence using [0]\n",
        "    # print(\"t == \",t)\n",
        "    # print(len(t)) # would be equal to number of columns\n",
        "\n",
        "    sorted_tags_i = sorted(range(len(t)), key = lambda i: t[i], reverse = True) \n",
        "                   # sorting in descending order and returns the indices(column number) of the list t.\n",
        "    # print(\"Sorted Tags == \",sorted_tags_i) # here sorted_tags_i contains the indices of tags sorted in decreasing order\n",
        "\n",
        "    multilabel_yn = multilabel_y[:,sorted_tags_i[:n]] # extracting all the entries with value == 1 in it but only of first n columns.\n",
        "\n",
        "    # print(type(multilabel_yn),\"\\n\",multilabel_yn)\n",
        "    # print(multilabel_yn.toarray())\n",
        "    return multilabel_yn\n"
      ],
      "metadata": {
        "id": "fgx2e1w8x9t9"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[0, 1, 7, 0],\n",
        "              [3, 0, 2, 19]])\n",
        "\n",
        "print(a)\n",
        "\n",
        "print(np.count_nonzero(a)) # returns #non zero values.\n",
        "\n",
        "print(np.count_nonzero(a == 0)) # returns the #entries where value == 0.\n",
        "\n",
        "print(np.count_nonzero(a,axis = 0)) # returns number of non zero entries along row.\n",
        "\n",
        "print(np.count_nonzero(a,axis = 1)) # returns number of non zero entries along columns."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVbE7k2Go_eC",
        "outputId": "840cde75-27f2-4834-a317-668117937311"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  1  7  0]\n",
            " [ 3  0  2 19]]\n",
            "5\n",
            "3\n",
            "[1 1 2 1]\n",
            "[2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def questions_explained_fn(n):\n",
        "    \n",
        "    \n",
        "    multilabel_yn = tags_to_choose(n) # it will return scipy matrix containing only 'n' tags.\n",
        "\n",
        "    x = multilabel_yn.sum(axis = 1) # returns total tags of each row, so X is a numpy matrix now instead of scipy sparse \n",
        "\n",
        "    # print(\"X--\\n\",x)\n",
        "    # print(\"np.CountNonZero == \",(np.count_nonzero(x == 0)))  \n",
        "\n",
        "    return (np.count_nonzero(x == 0)) # since we have already have summ of all the tags present in each row \n",
        "    \n",
        "    # hence it will return all the rows which has entries == 0 ."
      ],
      "metadata": {
        "id": "C4P6DTggSriT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "\n",
        "questions_explain = []\n",
        "\n",
        "total_tags = multilabel_y.shape[1]\n",
        "total_qs   = preprocessed_data.shape[0] # total number of rows are nothing but total number of questions .\n",
        "\n",
        "print(\"Total Tags == \",total_tags)\n",
        "print(\"Total Questions == \",total_qs)\n",
        "\n",
        "for i in range(500, total_tags, 500):\n",
        "  questions_explain.append( np.round(((total_qs - questions_explained_fn(i))/total_qs)*100,3) )\n",
        "                               # question_explained_fn() actually returning the number of questions that were not explained\n",
        "\n",
        "# let's say i = 3 that means n = 3 hence we will have to get the number of questions whose total sum along the top three column is non zero.\n",
        "\n",
        "print( \"total questions explained ==\",questions_explain)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9PmwfM7zse6",
        "outputId": "3c7505ea-e9d0-4c4c-e624-0fb2d46339bf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Tags ==  16321\n",
            "Total Questions ==  100000\n",
            "total questions explained == [92.5, 95.682, 97.073, 97.824, 98.336, 98.696, 98.945, 99.125, 99.287, 99.402, 99.481, 99.543, 99.599, 99.661, 99.712, 99.741, 99.766, 99.794, 99.813, 99.827, 99.859, 99.874, 99.882, 99.899, 99.912, 99.924, 99.936, 99.945, 99.959, 99.967, 99.979, 99.99]\n",
            "CPU times: user 446 ms, sys: 0 ns, total: 446 ms\n",
            "Wall time: 443 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions_explain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcZbsmLa0gXT",
        "outputId": "ec45fa12-5cbd-444b-ec75-0a98983ea1fd"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[92.5,\n",
              " 95.682,\n",
              " 97.073,\n",
              " 97.824,\n",
              " 98.336,\n",
              " 98.696,\n",
              " 98.945,\n",
              " 99.125,\n",
              " 99.287,\n",
              " 99.402,\n",
              " 99.481,\n",
              " 99.543,\n",
              " 99.599,\n",
              " 99.661,\n",
              " 99.712,\n",
              " 99.741,\n",
              " 99.766,\n",
              " 99.794,\n",
              " 99.813,\n",
              " 99.827,\n",
              " 99.859,\n",
              " 99.874,\n",
              " 99.882,\n",
              " 99.899,\n",
              " 99.912,\n",
              " 99.924,\n",
              " 99.936,\n",
              " 99.945,\n",
              " 99.959,\n",
              " 99.967,\n",
              " 99.979,\n",
              " 99.99]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xlabel = list(np.array(range(50,450,50))*5)\n",
        "\n",
        "xlabel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QPX-55w04VC",
        "outputId": "40b1c653-f711-4561-ce14-6a10f75cfeae"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[250, 500, 750, 1000, 1250, 1500, 1750, 2000]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xlabel = list(500 + np.array(range(-50,450,50))*50)\n",
        "\n",
        "xlabel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r78o5j5I5yXH",
        "outputId": "6961417f-85fb-435c-8fb3-514a6d7cc9c5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-2000, 500, 3000, 5500, 8000, 10500, 13000, 15500, 18000, 20500]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xlabel = list(500 + np.array(range(0,29587,500)))\n",
        "\n",
        "print(xlabel)\n",
        "print(questions_explain)\n",
        "\n",
        "print(len(questions_explain),len(xlabel))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2khpRN5m6VJr",
        "outputId": "bbc35c3d-c385-4023-acfd-ac8a7ab31497"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, 10000, 10500, 11000, 11500, 12000, 12500, 13000, 13500, 14000, 14500, 15000, 15500, 16000, 16500, 17000, 17500, 18000, 18500, 19000, 19500, 20000, 20500, 21000, 21500, 22000, 22500, 23000, 23500, 24000, 24500, 25000, 25500, 26000, 26500, 27000, 27500, 28000, 28500, 29000, 29500, 30000]\n",
            "[92.5, 95.682, 97.073, 97.824, 98.336, 98.696, 98.945, 99.125, 99.287, 99.402, 99.481, 99.543, 99.599, 99.661, 99.712, 99.741, 99.766, 99.794, 99.813, 99.827, 99.859, 99.874, 99.882, 99.899, 99.912, 99.924, 99.936, 99.945, 99.959, 99.967, 99.979, 99.99]\n",
            "32 60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,1)\n",
        "\n",
        "ax.plot(questions_explain)\n",
        "\n",
        "xlabel =  list(500 + np.array(range(0,29587,500)))\n",
        "\n",
        "ax.set_xticklabels(xlabel)\n",
        "\n",
        "plt.xlabel(\"Number of tags\")\n",
        "plt.ylabel(\"Number Questions coverd partially\")\n",
        "plt.grid()\n",
        "\n",
        "plt.show()\n",
        "# you can choose any number of tags based on your computing power, minimun is 50(it covers 90% of the tags)\n",
        "print(\"with \",500,\"tags we are covering \",questions_explain[0],\"% of questions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "oxP5fJCXzwxb",
        "outputId": "08fa91a1-eac0-4e21-de78-d6db3f9d4270"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "with  500 tags we are covering  92.5 % of questions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multilabel_yx = tags_to_choose(500)\n",
        "print(\"number of questions that are not covered :\", questions_explained_fn(500),\"out of \", total_qs)"
      ],
      "metadata": {
        "id": "Mvt1KyYqyH03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f5b341-e5c6-41c5-eda5-9084f6243682"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of questions that are not covered : 7500 out of  100000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the data into test and train (80:20)"
      ],
      "metadata": {
        "id": "-vUkqQE1790b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_size = preprocessed_data.shape[0]\n",
        "train_size = int(0.80*total_size)\n",
        "\n",
        "x_train = preprocessed_data.head(train_size)\n",
        "x_test  = preprocessed_data.tail(total_size - train_size)\n",
        "\n",
        "y_train = multilabel_yx[0:train_size,:]          # selecting all columns(2000)[that are basically nothing but one hot encoded Y_label(tags)] \n",
        "y_test  = multilabel_yx[train_size:total_size,:] # selecting rest of the remaining rows"
      ],
      "metadata": {
        "id": "_ORoI0BByIKw"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of data points in train data :\", y_train.shape)\n",
        "print(\"Number of data points in test data :\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwksHq-WoavW",
        "outputId": "041d77be-2b1f-4c92-e169-087cfa3ce945"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of data points in train data : (80000, 500)\n",
            "Number of data points in test data : (20000, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.tail(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "S7jWwR4woPmE",
        "outputId": "86a96f10-2e97-479c-f732-3f8fb65e223b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f8cfe5d5-a422-4d44-8795-7432a85f0b73\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>79998</th>\n",
              "      <td>abort read txt file updat matlab abort read tx...</td>\n",
              "      <td>matlab file-io concurrency locking text-files</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79999</th>\n",
              "      <td>abort run mstest unit test visualstudio 2012 a...</td>\n",
              "      <td>unit-testing visual-studio-2012 mstest</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8cfe5d5-a422-4d44-8795-7432a85f0b73')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8cfe5d5-a422-4d44-8795-7432a85f0b73 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8cfe5d5-a422-4d44-8795-7432a85f0b73');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                question                                           tags\n",
              "79998  abort read txt file updat matlab abort read tx...  matlab file-io concurrency locking text-files\n",
              "79999  abort run mstest unit test visualstudio 2012 a...         unit-testing visual-studio-2012 mstest"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# start = datetime.now() \n",
        "# Time taken to run this cell without using GPU: 0:05:21.570556\n",
        "# vectorizer = TfidfVectorizer(min_df = 0.0009, max_features = 20000, smooth_idf = True, norm =\"l2\", \\\n",
        "                            #  tokenizer = lambda x: x.split(), sublinear_tf = False, ngram_range=(1,3))\n",
        "# \n",
        "# x_train_multilabel = vectorizer.fit_transform(x_train['question'])\n",
        "# x_test_multilabel = vectorizer.transform(x_test['question'])\n",
        "\n",
        "# print(\"Time taken to run this cell without using GPU:\", datetime.now() - start)"
      ],
      "metadata": {
        "id": "ZZJv9ev18syg"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = datetime.now()\n",
        "vectorizer = TfidfVectorizer(min_df = 0.009, max_features = 700, smooth_idf = True, norm=\"l2\", \\\n",
        "                             tokenizer = lambda x: x.split(), sublinear_tf = False, ngram_range=(1,3))\n",
        "\n",
        "x_train_multilabel = vectorizer.fit_transform(x_train['question'])\n",
        "x_test_multilabel = vectorizer.transform(x_test['question'])\n",
        "\n",
        "print(\"Time taken to run this cell using GPU:\", datetime.now() - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAjmWtJ7qwkQ",
        "outputId": "69037a92-d3a6-464b-dc56-5141348ca4c0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to run this cell using GPU: 0:00:51.948921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dimensions of train data X:\",x_train_multilabel.shape, \"Y :\",y_train.shape)\n",
        "print(\"Dimensions of test data X:\",x_test_multilabel.shape,\"Y:\",y_test.shape) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wYdP3romEZ8",
        "outputId": "c932b276-4367-4747-a2b7-c9c80c9b9bc2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions of train data X: (80000, 700) Y : (80000, 500)\n",
            "Dimensions of test data X: (20000, 700) Y: (20000, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression with OneVsRest Classifier "
      ],
      "metadata": {
        "id": "VEIHSeUL3exe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Time taken to run this cell : 0:02:07.149196\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "classifier = OneVsRestClassifier(SGDClassifier(loss = 'log', alpha = 0.00001, penalty = 'l1'), n_jobs=-1)\n",
        "\n",
        "classifier.fit(x_train_multilabel, y_train)\n",
        "predictions = classifier.predict (x_test_multilabel)\n",
        "\n",
        "\n",
        "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
        "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
        "\n",
        "\n",
        "precision = precision_score(y_test, predictions, average='micro')\n",
        "recall    = recall_score(y_test, predictions, average='micro')\n",
        "f1        = f1_score(y_test, predictions, average='micro')\n",
        " \n",
        "print(\"Micro-average quality numbers\")\n",
        "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
        "\n",
        "precision = precision_score(y_test, predictions, average='macro')\n",
        "recall    = recall_score(y_test, predictions, average='macro')\n",
        "f1        = f1_score(y_test, predictions, average='macro')\n",
        " \n",
        "print(\"Macro-average quality numbers\")\n",
        "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
        "\n",
        "print (metrics.classification_report(y_test, predictions))\n",
        "print(\"Time taken to run this cell :\", datetime.now() - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Njm3Kcdpy59W",
        "outputId": "1c234358-d035-45f2-c8f1-116c0461e0e1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.14235\n",
            "Hamming loss  0.0033828\n",
            "Micro-average quality numbers\n",
            "Precision: 0.6815, Recall: 0.1826, F1-measure: 0.2880\n",
            "Macro-average quality numbers\n",
            "Precision: 0.2312, Recall: 0.0708, F1-measure: 0.0970\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.33      0.47       820\n",
            "           1       0.73      0.10      0.17      1931\n",
            "           2       0.64      0.11      0.18       544\n",
            "           3       0.64      0.21      0.32       222\n",
            "           4       0.83      0.43      0.57      1311\n",
            "           5       0.91      0.45      0.60      1014\n",
            "           6       0.84      0.32      0.46      1374\n",
            "           7       0.85      0.54      0.66       702\n",
            "           8       0.88      0.52      0.65      1424\n",
            "           9       0.86      0.08      0.14      1037\n",
            "          10       0.79      0.43      0.55       797\n",
            "          11       0.71      0.38      0.50       156\n",
            "          12       0.71      0.28      0.40        36\n",
            "          13       0.81      0.35      0.49       610\n",
            "          14       0.51      0.20      0.29       405\n",
            "          15       0.83      0.17      0.28       144\n",
            "          16       0.66      0.19      0.30       425\n",
            "          17       0.46      0.05      0.09       485\n",
            "          18       0.82      0.60      0.70       269\n",
            "          19       0.94      0.54      0.68       518\n",
            "          20       0.66      0.12      0.20       529\n",
            "          21       0.86      0.54      0.66       294\n",
            "          22       0.84      0.35      0.49       520\n",
            "          23       0.64      0.26      0.37       246\n",
            "          24       0.65      0.19      0.30       312\n",
            "          25       0.56      0.26      0.36       314\n",
            "          26       0.00      0.00      0.00       190\n",
            "          27       0.33      0.08      0.12       342\n",
            "          28       0.57      0.18      0.27        96\n",
            "          29       0.00      0.00      0.00        32\n",
            "          30       0.38      0.16      0.23       747\n",
            "          31       0.50      0.07      0.12        14\n",
            "          32       0.58      0.45      0.50       166\n",
            "          33       0.59      0.26      0.36       171\n",
            "          34       0.13      0.01      0.01       256\n",
            "          35       0.82      0.58      0.68       199\n",
            "          36       0.00      0.00      0.00        60\n",
            "          37       0.33      0.20      0.25       203\n",
            "          38       0.69      0.48      0.56       201\n",
            "          39       0.43      0.11      0.17       208\n",
            "          40       0.25      0.08      0.12        13\n",
            "          41       0.00      0.00      0.00       154\n",
            "          42       0.40      0.23      0.29        69\n",
            "          43       0.00      0.00      0.00       426\n",
            "          44       0.51      0.29      0.37        77\n",
            "          45       0.55      0.30      0.38       223\n",
            "          46       0.53      0.06      0.11       144\n",
            "          47       0.00      0.00      0.00       245\n",
            "          48       0.38      0.03      0.06        91\n",
            "          49       0.59      0.18      0.28       157\n",
            "          50       0.59      0.18      0.28       132\n",
            "          51       0.72      0.32      0.44        41\n",
            "          52       0.61      0.35      0.44       124\n",
            "          53       0.23      0.20      0.21        96\n",
            "          54       0.21      0.06      0.10       128\n",
            "          55       0.57      0.28      0.38        46\n",
            "          56       0.46      0.07      0.13       151\n",
            "          57       1.00      0.01      0.02        80\n",
            "          58       0.31      0.08      0.12        65\n",
            "          59       0.52      0.16      0.24       182\n",
            "          60       0.67      0.05      0.10       148\n",
            "          61       0.45      0.07      0.12       196\n",
            "          62       0.47      0.16      0.23        58\n",
            "          63       0.50      0.02      0.04        43\n",
            "          64       0.00      0.00      0.00       197\n",
            "          65       0.65      0.38      0.48        82\n",
            "          66       0.62      0.10      0.17        50\n",
            "          67       0.68      0.45      0.54       105\n",
            "          68       0.25      0.05      0.08        98\n",
            "          69       0.23      0.05      0.08       238\n",
            "          70       0.00      0.00      0.00        35\n",
            "          71       0.41      0.30      0.34        54\n",
            "          72       0.30      0.12      0.17        25\n",
            "          73       0.50      0.10      0.17        29\n",
            "          74       0.00      0.00      0.00        29\n",
            "          75       0.67      0.05      0.09        40\n",
            "          76       0.75      0.03      0.06       105\n",
            "          77       1.00      0.14      0.25        28\n",
            "          78       0.18      0.01      0.03       202\n",
            "          79       0.52      0.43      0.47        37\n",
            "          80       1.00      0.33      0.50        15\n",
            "          81       0.32      0.21      0.26        52\n",
            "          82       0.29      0.18      0.22        50\n",
            "          83       0.17      0.02      0.03        56\n",
            "          84       0.00      0.00      0.00        54\n",
            "          85       0.50      0.38      0.43        34\n",
            "          86       0.62      0.17      0.26        30\n",
            "          87       0.38      0.17      0.24        29\n",
            "          88       0.70      0.29      0.41        24\n",
            "          89       0.83      0.59      0.69       117\n",
            "          90       0.06      0.02      0.02        66\n",
            "          91       0.50      0.09      0.15        68\n",
            "          92       0.00      0.00      0.00        67\n",
            "          93       0.45      0.32      0.38        28\n",
            "          94       0.08      0.12      0.10        17\n",
            "          95       0.00      0.00      0.00        51\n",
            "          96       0.00      0.00      0.00        53\n",
            "          97       0.50      0.03      0.06        61\n",
            "          98       0.00      0.00      0.00        79\n",
            "          99       0.75      0.33      0.46        18\n",
            "         100       0.00      0.00      0.00        11\n",
            "         101       0.00      0.00      0.00       207\n",
            "         102       0.00      0.00      0.00         6\n",
            "         103       0.33      0.03      0.06        30\n",
            "         104       0.50      0.04      0.07        54\n",
            "         105       0.00      0.00      0.00        39\n",
            "         106       0.30      0.10      0.15        70\n",
            "         107       0.00      0.00      0.00        14\n",
            "         108       0.00      0.00      0.00        66\n",
            "         109       0.56      0.20      0.29        50\n",
            "         110       0.00      0.00      0.00        87\n",
            "         111       0.57      0.16      0.25        51\n",
            "         112       0.00      0.00      0.00       291\n",
            "         113       0.83      0.10      0.18        49\n",
            "         114       0.33      0.01      0.02       110\n",
            "         115       0.11      0.04      0.05        28\n",
            "         116       0.00      0.00      0.00         5\n",
            "         117       0.56      0.09      0.15        56\n",
            "         118       0.00      0.00      0.00       125\n",
            "         119       0.83      0.34      0.48        44\n",
            "         120       0.62      0.12      0.20        42\n",
            "         121       0.63      0.22      0.32        55\n",
            "         122       0.79      0.54      0.64        68\n",
            "         123       1.00      0.01      0.02        82\n",
            "         124       0.00      0.00      0.00         0\n",
            "         125       0.00      0.00      0.00         7\n",
            "         126       0.33      0.06      0.10        18\n",
            "         127       0.80      0.13      0.22        31\n",
            "         128       0.75      0.23      0.35        13\n",
            "         129       0.00      0.00      0.00        50\n",
            "         130       0.00      0.00      0.00        91\n",
            "         131       0.25      0.03      0.05        35\n",
            "         132       0.38      0.12      0.18        26\n",
            "         133       0.00      0.00      0.00        32\n",
            "         134       0.38      0.09      0.14        35\n",
            "         135       0.00      0.00      0.00        37\n",
            "         136       0.00      0.00      0.00        55\n",
            "         137       0.43      0.29      0.35        41\n",
            "         138       0.25      0.07      0.11        15\n",
            "         139       0.45      0.10      0.17        99\n",
            "         140       0.00      0.00      0.00        86\n",
            "         141       0.53      0.17      0.26        53\n",
            "         142       0.20      0.03      0.05        36\n",
            "         143       0.00      0.00      0.00        66\n",
            "         144       0.50      0.03      0.06        64\n",
            "         145       0.00      0.00      0.00        25\n",
            "         146       0.25      0.02      0.04       125\n",
            "         147       0.33      0.27      0.30        15\n",
            "         148       0.00      0.00      0.00        48\n",
            "         149       0.38      0.22      0.27        65\n",
            "         150       0.50      0.09      0.15        11\n",
            "         151       0.00      0.00      0.00        15\n",
            "         152       0.37      0.19      0.25        52\n",
            "         153       0.55      0.33      0.41        18\n",
            "         154       0.00      0.00      0.00        16\n",
            "         155       0.00      0.00      0.00        20\n",
            "         156       0.49      0.17      0.25       121\n",
            "         157       0.00      0.00      0.00       107\n",
            "         158       0.00      0.00      0.00        15\n",
            "         159       0.00      0.00      0.00       105\n",
            "         160       0.50      0.01      0.03        69\n",
            "         161       0.56      0.27      0.36        56\n",
            "         162       0.00      0.00      0.00        47\n",
            "         163       0.00      0.00      0.00       121\n",
            "         164       0.39      0.17      0.24        41\n",
            "         165       0.00      0.00      0.00       229\n",
            "         166       1.00      0.01      0.02        98\n",
            "         167       0.00      0.00      0.00        33\n",
            "         168       0.50      0.09      0.15        44\n",
            "         169       0.00      0.00      0.00        45\n",
            "         170       0.00      0.00      0.00        51\n",
            "         171       0.00      0.00      0.00        18\n",
            "         172       0.69      0.56      0.62        48\n",
            "         173       1.00      0.17      0.29        12\n",
            "         174       0.29      0.10      0.14        62\n",
            "         175       0.00      0.00      0.00        44\n",
            "         176       0.48      0.37      0.42        30\n",
            "         177       0.00      0.00      0.00        30\n",
            "         178       0.00      0.00      0.00         0\n",
            "         179       0.00      0.00      0.00         1\n",
            "         180       1.00      0.03      0.05        40\n",
            "         181       0.22      0.05      0.08        44\n",
            "         182       0.00      0.00      0.00         2\n",
            "         183       0.75      0.04      0.08        75\n",
            "         184       0.00      0.00      0.00         4\n",
            "         185       0.59      0.27      0.37        64\n",
            "         186       0.00      0.00      0.00        12\n",
            "         187       0.00      0.00      0.00        55\n",
            "         188       0.50      0.03      0.06        64\n",
            "         189       0.00      0.00      0.00        96\n",
            "         190       0.00      0.00      0.00        22\n",
            "         191       0.00      0.00      0.00        76\n",
            "         192       0.43      0.07      0.12        45\n",
            "         193       0.60      0.21      0.32        14\n",
            "         194       0.00      0.00      0.00        50\n",
            "         195       0.00      0.00      0.00        20\n",
            "         196       0.00      0.00      0.00        35\n",
            "         197       0.71      0.21      0.33        94\n",
            "         198       0.00      0.00      0.00        14\n",
            "         199       0.00      0.00      0.00        25\n",
            "         200       0.00      0.00      0.00        54\n",
            "         201       0.00      0.00      0.00        22\n",
            "         202       0.50      0.07      0.12        43\n",
            "         203       0.00      0.00      0.00        43\n",
            "         204       0.78      0.23      0.35        62\n",
            "         205       0.00      0.00      0.00         3\n",
            "         206       0.12      0.05      0.07        43\n",
            "         207       0.00      0.00      0.00         7\n",
            "         208       0.20      0.12      0.15         8\n",
            "         209       0.00      0.00      0.00        42\n",
            "         210       0.00      0.00      0.00        10\n",
            "         211       0.00      0.00      0.00        40\n",
            "         212       0.00      0.00      0.00        23\n",
            "         213       0.00      0.00      0.00         6\n",
            "         214       0.67      0.04      0.08        47\n",
            "         215       0.00      0.00      0.00        62\n",
            "         216       0.00      0.00      0.00        77\n",
            "         217       0.00      0.00      0.00        22\n",
            "         218       0.00      0.00      0.00         3\n",
            "         219       0.00      0.00      0.00        28\n",
            "         220       0.00      0.00      0.00        81\n",
            "         221       0.20      0.03      0.06        31\n",
            "         222       0.50      0.03      0.06        34\n",
            "         223       0.00      0.00      0.00        60\n",
            "         224       0.00      0.00      0.00        10\n",
            "         225       0.25      0.10      0.14        10\n",
            "         226       1.00      0.03      0.06        92\n",
            "         227       1.00      0.15      0.27        13\n",
            "         228       0.00      0.00      0.00        13\n",
            "         229       0.00      0.00      0.00        43\n",
            "         230       0.56      0.14      0.23        35\n",
            "         231       0.00      0.00      0.00         4\n",
            "         232       0.00      0.00      0.00        20\n",
            "         233       0.00      0.00      0.00       145\n",
            "         234       0.00      0.00      0.00        55\n",
            "         235       0.00      0.00      0.00         2\n",
            "         236       0.46      0.16      0.24        37\n",
            "         237       0.00      0.00      0.00        90\n",
            "         238       0.00      0.00      0.00        58\n",
            "         239       0.00      0.00      0.00        20\n",
            "         240       0.00      0.00      0.00        61\n",
            "         241       0.00      0.00      0.00        42\n",
            "         242       0.00      0.00      0.00        30\n",
            "         243       0.33      0.02      0.03        66\n",
            "         244       0.00      0.00      0.00        42\n",
            "         245       0.11      0.03      0.05        31\n",
            "         246       0.10      0.17      0.12         6\n",
            "         247       0.00      0.00      0.00        18\n",
            "         248       0.00      0.00      0.00        51\n",
            "         249       0.00      0.00      0.00        17\n",
            "         250       0.00      0.00      0.00        22\n",
            "         251       0.00      0.00      0.00        52\n",
            "         252       0.11      0.03      0.05        29\n",
            "         253       0.00      0.00      0.00        28\n",
            "         254       0.00      0.00      0.00        10\n",
            "         255       0.00      0.00      0.00         5\n",
            "         256       0.00      0.00      0.00         3\n",
            "         257       0.50      0.02      0.05        41\n",
            "         258       1.00      0.03      0.06        30\n",
            "         259       0.00      0.00      0.00         3\n",
            "         260       1.00      0.03      0.05        38\n",
            "         261       0.00      0.00      0.00         1\n",
            "         262       0.00      0.00      0.00        19\n",
            "         263       0.00      0.00      0.00        14\n",
            "         264       1.00      0.03      0.05        37\n",
            "         265       0.00      0.00      0.00         9\n",
            "         266       0.21      0.09      0.12        45\n",
            "         267       0.48      0.30      0.37        33\n",
            "         268       0.00      0.00      0.00        16\n",
            "         269       0.00      0.00      0.00        35\n",
            "         270       0.00      0.00      0.00        11\n",
            "         271       0.00      0.00      0.00        30\n",
            "         272       0.38      0.38      0.38         8\n",
            "         273       0.25      0.05      0.08        21\n",
            "         274       0.00      0.00      0.00       123\n",
            "         275       0.00      0.00      0.00        67\n",
            "         276       0.00      0.00      0.00        20\n",
            "         277       0.00      0.00      0.00        14\n",
            "         278       0.00      0.00      0.00        19\n",
            "         279       0.00      0.00      0.00        12\n",
            "         280       0.00      0.00      0.00        15\n",
            "         281       0.00      0.00      0.00        17\n",
            "         282       0.00      0.00      0.00        41\n",
            "         283       0.00      0.00      0.00        15\n",
            "         284       0.00      0.00      0.00        74\n",
            "         285       0.00      0.00      0.00        38\n",
            "         286       0.10      0.06      0.08        16\n",
            "         287       0.00      0.00      0.00        30\n",
            "         288       0.00      0.00      0.00        28\n",
            "         289       0.00      0.00      0.00        21\n",
            "         290       0.00      0.00      0.00        41\n",
            "         291       0.00      0.00      0.00        12\n",
            "         292       0.50      0.04      0.08        24\n",
            "         293       0.47      0.45      0.46        20\n",
            "         294       0.00      0.00      0.00        23\n",
            "         295       0.00      0.00      0.00        29\n",
            "         296       0.00      0.00      0.00        28\n",
            "         297       0.00      0.00      0.00        42\n",
            "         298       0.00      0.00      0.00        53\n",
            "         299       0.00      0.00      0.00        36\n",
            "         300       0.40      0.05      0.09        41\n",
            "         301       0.00      0.00      0.00        37\n",
            "         302       0.00      0.00      0.00        26\n",
            "         303       0.14      0.09      0.11        11\n",
            "         304       0.00      0.00      0.00        31\n",
            "         305       0.00      0.00      0.00        17\n",
            "         306       0.00      0.00      0.00         9\n",
            "         307       0.00      0.00      0.00         6\n",
            "         308       0.00      0.00      0.00        34\n",
            "         309       0.69      0.21      0.32        43\n",
            "         310       0.00      0.00      0.00        30\n",
            "         311       0.80      0.08      0.15        50\n",
            "         312       0.00      0.00      0.00        24\n",
            "         313       0.00      0.00      0.00        42\n",
            "         314       0.00      0.00      0.00        22\n",
            "         315       1.00      0.02      0.03        58\n",
            "         316       0.00      0.00      0.00        10\n",
            "         317       0.40      0.28      0.33        57\n",
            "         318       1.00      0.10      0.18        10\n",
            "         319       0.00      0.00      0.00        11\n",
            "         320       1.00      0.09      0.17        11\n",
            "         321       0.00      0.00      0.00         8\n",
            "         322       0.00      0.00      0.00        22\n",
            "         323       0.00      0.00      0.00        28\n",
            "         324       0.00      0.00      0.00        50\n",
            "         325       0.50      0.06      0.10        18\n",
            "         326       1.00      0.03      0.06        33\n",
            "         327       0.29      0.12      0.17        17\n",
            "         328       0.67      0.07      0.12        29\n",
            "         329       0.00      0.00      0.00         7\n",
            "         330       0.00      0.00      0.00        10\n",
            "         331       0.33      0.04      0.07        25\n",
            "         332       0.00      0.00      0.00         2\n",
            "         333       0.38      0.27      0.32        11\n",
            "         334       0.00      0.00      0.00        24\n",
            "         335       0.00      0.00      0.00         5\n",
            "         336       0.00      0.00      0.00        33\n",
            "         337       0.00      0.00      0.00        30\n",
            "         338       0.00      0.00      0.00        42\n",
            "         339       0.00      0.00      0.00        26\n",
            "         340       0.00      0.00      0.00        36\n",
            "         341       0.00      0.00      0.00        13\n",
            "         342       0.00      0.00      0.00        11\n",
            "         343       0.00      0.00      0.00        10\n",
            "         344       0.32      0.29      0.30        21\n",
            "         345       0.00      0.00      0.00         0\n",
            "         346       0.00      0.00      0.00         6\n",
            "         347       0.50      0.17      0.25        12\n",
            "         348       0.50      0.08      0.13        13\n",
            "         349       0.00      0.00      0.00        24\n",
            "         350       0.00      0.00      0.00        27\n",
            "         351       0.53      0.21      0.30        43\n",
            "         352       0.00      0.00      0.00        30\n",
            "         353       0.00      0.00      0.00        22\n",
            "         354       0.00      0.00      0.00        31\n",
            "         355       0.00      0.00      0.00        10\n",
            "         356       1.00      0.15      0.26        20\n",
            "         357       0.00      0.00      0.00        20\n",
            "         358       0.00      0.00      0.00        28\n",
            "         359       0.62      0.24      0.34        21\n",
            "         360       0.00      0.00      0.00        25\n",
            "         361       1.00      0.03      0.06        35\n",
            "         362       0.00      0.00      0.00        36\n",
            "         363       0.00      0.00      0.00        17\n",
            "         364       0.00      0.00      0.00        13\n",
            "         365       0.00      0.00      0.00        21\n",
            "         366       0.00      0.00      0.00        18\n",
            "         367       0.00      0.00      0.00        97\n",
            "         368       0.00      0.00      0.00        29\n",
            "         369       0.00      0.00      0.00        12\n",
            "         370       0.00      0.00      0.00        13\n",
            "         371       0.25      0.06      0.09        18\n",
            "         372       0.00      0.00      0.00         6\n",
            "         373       0.00      0.00      0.00         6\n",
            "         374       0.00      0.00      0.00        30\n",
            "         375       0.56      0.19      0.28        27\n",
            "         376       0.00      0.00      0.00        28\n",
            "         377       0.00      0.00      0.00         2\n",
            "         378       0.00      0.00      0.00         4\n",
            "         379       0.00      0.00      0.00        19\n",
            "         380       0.00      0.00      0.00         5\n",
            "         381       0.00      0.00      0.00        18\n",
            "         382       0.00      0.00      0.00        22\n",
            "         383       0.00      0.00      0.00        16\n",
            "         384       0.57      0.31      0.40        13\n",
            "         385       0.17      0.11      0.13        18\n",
            "         386       0.00      0.00      0.00        11\n",
            "         387       0.00      0.00      0.00        88\n",
            "         388       0.50      0.08      0.13        13\n",
            "         389       0.00      0.00      0.00         6\n",
            "         390       0.00      0.00      0.00         6\n",
            "         391       0.00      0.00      0.00        51\n",
            "         392       0.00      0.00      0.00        13\n",
            "         393       0.00      0.00      0.00        37\n",
            "         394       0.00      0.00      0.00         6\n",
            "         395       0.00      0.00      0.00         9\n",
            "         396       0.00      0.00      0.00        13\n",
            "         397       0.00      0.00      0.00         6\n",
            "         398       0.33      0.03      0.06        29\n",
            "         399       0.00      0.00      0.00        33\n",
            "         400       0.00      0.00      0.00        31\n",
            "         401       0.56      0.10      0.17        50\n",
            "         402       0.00      0.00      0.00        18\n",
            "         403       0.00      0.00      0.00         7\n",
            "         404       0.00      0.00      0.00        26\n",
            "         405       0.25      0.05      0.09        56\n",
            "         406       0.00      0.00      0.00         4\n",
            "         407       0.00      0.00      0.00        17\n",
            "         408       0.00      0.00      0.00        11\n",
            "         409       0.00      0.00      0.00        18\n",
            "         410       0.00      0.00      0.00        10\n",
            "         411       0.00      0.00      0.00        45\n",
            "         412       0.00      0.00      0.00        20\n",
            "         413       0.00      0.00      0.00        25\n",
            "         414       0.00      0.00      0.00        20\n",
            "         415       0.00      0.00      0.00         6\n",
            "         416       0.33      0.04      0.07        26\n",
            "         417       0.00      0.00      0.00        10\n",
            "         418       0.00      0.00      0.00        18\n",
            "         419       0.00      0.00      0.00         6\n",
            "         420       0.50      0.12      0.19        17\n",
            "         421       0.00      0.00      0.00         1\n",
            "         422       0.00      0.00      0.00         6\n",
            "         423       0.00      0.00      0.00        12\n",
            "         424       0.00      0.00      0.00         4\n",
            "         425       1.00      0.18      0.31        11\n",
            "         426       0.00      0.00      0.00        11\n",
            "         427       0.00      0.00      0.00         8\n",
            "         428       0.00      0.00      0.00        26\n",
            "         429       0.00      0.00      0.00        40\n",
            "         430       0.00      0.00      0.00         2\n",
            "         431       0.00      0.00      0.00        35\n",
            "         432       0.00      0.00      0.00        15\n",
            "         433       0.00      0.00      0.00        18\n",
            "         434       0.00      0.00      0.00         0\n",
            "         435       0.00      0.00      0.00         0\n",
            "         436       0.50      0.04      0.07        28\n",
            "         437       0.00      0.00      0.00        33\n",
            "         438       0.00      0.00      0.00        20\n",
            "         439       0.00      0.00      0.00        36\n",
            "         440       1.00      0.06      0.11        18\n",
            "         441       0.00      0.00      0.00        18\n",
            "         442       0.00      0.00      0.00        16\n",
            "         443       0.00      0.00      0.00        22\n",
            "         444       0.00      0.00      0.00         6\n",
            "         445       0.00      0.00      0.00        21\n",
            "         446       0.00      0.00      0.00        46\n",
            "         447       0.00      0.00      0.00        69\n",
            "         448       0.00      0.00      0.00         7\n",
            "         449       0.00      0.00      0.00         3\n",
            "         450       0.00      0.00      0.00        52\n",
            "         451       0.00      0.00      0.00        16\n",
            "         452       0.00      0.00      0.00        17\n",
            "         453       0.00      0.00      0.00        13\n",
            "         454       0.00      0.00      0.00        11\n",
            "         455       0.00      0.00      0.00        12\n",
            "         456       0.00      0.00      0.00         6\n",
            "         457       0.00      0.00      0.00        18\n",
            "         458       1.00      0.07      0.12        15\n",
            "         459       0.00      0.00      0.00        28\n",
            "         460       0.00      0.00      0.00        18\n",
            "         461       0.00      0.00      0.00        10\n",
            "         462       0.00      0.00      0.00        24\n",
            "         463       1.00      0.06      0.11        18\n",
            "         464       0.00      0.00      0.00        39\n",
            "         465       1.00      0.09      0.17        11\n",
            "         466       0.17      0.03      0.05        35\n",
            "         467       0.17      0.10      0.12        21\n",
            "         468       0.00      0.00      0.00        37\n",
            "         469       0.00      0.00      0.00         5\n",
            "         470       1.00      0.12      0.22         8\n",
            "         471       0.00      0.00      0.00        37\n",
            "         472       0.00      0.00      0.00        47\n",
            "         473       0.00      0.00      0.00        14\n",
            "         474       0.00      0.00      0.00        23\n",
            "         475       0.00      0.00      0.00        66\n",
            "         476       0.00      0.00      0.00         3\n",
            "         477       0.00      0.00      0.00        19\n",
            "         478       0.00      0.00      0.00         1\n",
            "         479       0.00      0.00      0.00        23\n",
            "         480       0.00      0.00      0.00        60\n",
            "         481       0.00      0.00      0.00        26\n",
            "         482       0.00      0.00      0.00         4\n",
            "         483       0.00      0.00      0.00         8\n",
            "         484       0.00      0.00      0.00        23\n",
            "         485       0.00      0.00      0.00        18\n",
            "         486       0.00      0.00      0.00        12\n",
            "         487       0.00      0.00      0.00        29\n",
            "         488       1.00      1.00      1.00         1\n",
            "         489       1.00      0.17      0.29         6\n",
            "         490       0.40      0.29      0.33         7\n",
            "         491       0.00      0.00      0.00         3\n",
            "         492       0.00      0.00      0.00        10\n",
            "         493       0.00      0.00      0.00        19\n",
            "         494       0.00      0.00      0.00         7\n",
            "         495       1.00      0.12      0.22         8\n",
            "         496       0.00      0.00      0.00        18\n",
            "         497       0.00      0.00      0.00        72\n",
            "         498       0.00      0.00      0.00         8\n",
            "         499       0.00      0.00      0.00        32\n",
            "\n",
            "   micro avg       0.68      0.18      0.29     37472\n",
            "   macro avg       0.23      0.07      0.10     37472\n",
            "weighted avg       0.49      0.18      0.25     37472\n",
            " samples avg       0.28      0.18      0.21     37472\n",
            "\n",
            "Time taken to run this cell : 0:02:07.149196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Time taken to run this cell : 0:03:41.090821\n",
        "start = datetime.now()\n",
        "\n",
        "classifier_2 = OneVsRestClassifier(LogisticRegression(penalty='l2'), n_jobs=-1)\n",
        "\n",
        "classifier_2.fit(x_train_multilabel, y_train)\n",
        "predictions_2 = classifier_2.predict(x_test_multilabel)\n",
        "\n",
        "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions_2))\n",
        "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions_2))\n",
        "\n",
        "\n",
        "precision = precision_score(y_test, predictions_2, average='micro')\n",
        "recall = recall_score(y_test, predictions_2, average='micro')\n",
        "f1 = f1_score(y_test, predictions_2, average='micro')\n",
        " \n",
        "print(\"Micro-average quality numbers\")\n",
        "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
        "\n",
        "precision = precision_score(y_test, predictions_2, average='macro')\n",
        "recall = recall_score(y_test, predictions_2, average='macro')\n",
        "f1 = f1_score(y_test, predictions_2, average='macro')\n",
        " \n",
        "print(\"Macro-average quality numbers\")\n",
        "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
        "\n",
        "print (metrics.classification_report(y_test, predictions_2))\n",
        "print(\"Time taken to run this cell :\", datetime.now() - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukThCG-A6o2i",
        "outputId": "5e147d24-7cad-4dc7-f96f-6c40008dac89"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.1409\n",
            "Hamming loss  0.0033598\n",
            "Micro-average quality numbers\n",
            "Precision: 0.7423, Recall: 0.1584, F1-measure: 0.2610\n",
            "Macro-average quality numbers\n",
            "Precision: 0.1952, Recall: 0.0502, F1-measure: 0.0729\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.33      0.47       820\n",
            "           1       0.73      0.10      0.17      1931\n",
            "           2       0.66      0.10      0.18       544\n",
            "           3       0.62      0.21      0.31       222\n",
            "           4       0.84      0.41      0.55      1311\n",
            "           5       0.92      0.42      0.58      1014\n",
            "           6       0.85      0.30      0.45      1374\n",
            "           7       0.87      0.52      0.65       702\n",
            "           8       0.91      0.46      0.61      1424\n",
            "           9       0.88      0.07      0.13      1037\n",
            "          10       0.81      0.38      0.51       797\n",
            "          11       0.71      0.37      0.49       156\n",
            "          12       0.71      0.28      0.40        36\n",
            "          13       0.83      0.31      0.46       610\n",
            "          14       0.52      0.16      0.24       405\n",
            "          15       0.80      0.14      0.24       144\n",
            "          16       0.69      0.16      0.26       425\n",
            "          17       0.45      0.02      0.04       485\n",
            "          18       0.85      0.51      0.64       269\n",
            "          19       0.95      0.48      0.64       518\n",
            "          20       0.68      0.10      0.18       529\n",
            "          21       0.86      0.52      0.65       294\n",
            "          22       0.84      0.29      0.44       520\n",
            "          23       0.65      0.22      0.33       246\n",
            "          24       0.76      0.16      0.26       312\n",
            "          25       0.58      0.20      0.30       314\n",
            "          26       0.00      0.00      0.00       190\n",
            "          27       0.31      0.04      0.07       342\n",
            "          28       0.52      0.12      0.20        96\n",
            "          29       0.00      0.00      0.00        32\n",
            "          30       0.45      0.08      0.13       747\n",
            "          31       0.50      0.07      0.12        14\n",
            "          32       0.59      0.42      0.49       166\n",
            "          33       0.59      0.25      0.35       171\n",
            "          34       0.22      0.01      0.02       256\n",
            "          35       0.83      0.52      0.64       199\n",
            "          36       0.00      0.00      0.00        60\n",
            "          37       0.37      0.14      0.21       203\n",
            "          38       0.70      0.42      0.53       201\n",
            "          39       0.44      0.09      0.15       208\n",
            "          40       0.33      0.08      0.12        13\n",
            "          41       0.00      0.00      0.00       154\n",
            "          42       0.50      0.26      0.34        69\n",
            "          43       0.00      0.00      0.00       426\n",
            "          44       0.59      0.25      0.35        77\n",
            "          45       0.58      0.25      0.35       223\n",
            "          46       0.54      0.05      0.09       144\n",
            "          47       0.00      0.00      0.00       245\n",
            "          48       0.67      0.04      0.08        91\n",
            "          49       0.80      0.15      0.26       157\n",
            "          50       0.44      0.09      0.15       132\n",
            "          51       0.85      0.27      0.41        41\n",
            "          52       0.64      0.35      0.45       124\n",
            "          53       0.26      0.20      0.22        96\n",
            "          54       0.18      0.04      0.06       128\n",
            "          55       0.62      0.22      0.32        46\n",
            "          56       0.60      0.06      0.11       151\n",
            "          57       0.00      0.00      0.00        80\n",
            "          58       0.45      0.08      0.13        65\n",
            "          59       0.52      0.08      0.14       182\n",
            "          60       0.50      0.01      0.01       148\n",
            "          61       0.57      0.06      0.11       196\n",
            "          62       0.40      0.10      0.16        58\n",
            "          63       0.00      0.00      0.00        43\n",
            "          64       0.00      0.00      0.00       197\n",
            "          65       0.67      0.32      0.43        82\n",
            "          66       0.67      0.04      0.08        50\n",
            "          67       0.69      0.39      0.50       105\n",
            "          68       0.19      0.03      0.05        98\n",
            "          69       0.19      0.02      0.03       238\n",
            "          70       0.00      0.00      0.00        35\n",
            "          71       0.64      0.26      0.37        54\n",
            "          72       0.40      0.08      0.13        25\n",
            "          73       0.50      0.10      0.17        29\n",
            "          74       0.50      0.03      0.06        29\n",
            "          75       0.50      0.03      0.05        40\n",
            "          76       1.00      0.01      0.02       105\n",
            "          77       1.00      0.11      0.19        28\n",
            "          78       0.50      0.00      0.01       202\n",
            "          79       0.57      0.43      0.49        37\n",
            "          80       0.83      0.33      0.48        15\n",
            "          81       0.39      0.21      0.28        52\n",
            "          82       0.22      0.08      0.12        50\n",
            "          83       0.25      0.02      0.03        56\n",
            "          84       0.00      0.00      0.00        54\n",
            "          85       0.55      0.35      0.43        34\n",
            "          86       0.67      0.20      0.31        30\n",
            "          87       0.42      0.17      0.24        29\n",
            "          88       0.70      0.29      0.41        24\n",
            "          89       0.86      0.46      0.60       117\n",
            "          90       0.00      0.00      0.00        66\n",
            "          91       0.44      0.06      0.10        68\n",
            "          92       0.00      0.00      0.00        67\n",
            "          93       0.53      0.29      0.37        28\n",
            "          94       0.06      0.06      0.06        17\n",
            "          95       0.00      0.00      0.00        51\n",
            "          96       0.00      0.00      0.00        53\n",
            "          97       1.00      0.02      0.03        61\n",
            "          98       0.00      0.00      0.00        79\n",
            "          99       0.83      0.28      0.42        18\n",
            "         100       0.00      0.00      0.00        11\n",
            "         101       0.00      0.00      0.00       207\n",
            "         102       0.00      0.00      0.00         6\n",
            "         103       0.50      0.03      0.06        30\n",
            "         104       1.00      0.02      0.04        54\n",
            "         105       0.00      0.00      0.00        39\n",
            "         106       0.43      0.09      0.14        70\n",
            "         107       0.00      0.00      0.00        14\n",
            "         108       0.00      0.00      0.00        66\n",
            "         109       0.75      0.18      0.29        50\n",
            "         110       0.00      0.00      0.00        87\n",
            "         111       0.60      0.12      0.20        51\n",
            "         112       0.00      0.00      0.00       291\n",
            "         113       1.00      0.04      0.08        49\n",
            "         114       1.00      0.01      0.02       110\n",
            "         115       0.00      0.00      0.00        28\n",
            "         116       0.00      0.00      0.00         5\n",
            "         117       0.67      0.04      0.07        56\n",
            "         118       0.00      0.00      0.00       125\n",
            "         119       0.85      0.25      0.39        44\n",
            "         120       0.71      0.12      0.20        42\n",
            "         121       0.67      0.11      0.19        55\n",
            "         122       0.81      0.37      0.51        68\n",
            "         123       1.00      0.01      0.02        82\n",
            "         124       0.00      0.00      0.00         0\n",
            "         125       0.00      0.00      0.00         7\n",
            "         126       0.50      0.06      0.10        18\n",
            "         127       1.00      0.16      0.28        31\n",
            "         128       1.00      0.15      0.27        13\n",
            "         129       0.00      0.00      0.00        50\n",
            "         130       0.00      0.00      0.00        91\n",
            "         131       0.20      0.03      0.05        35\n",
            "         132       0.75      0.12      0.20        26\n",
            "         133       0.00      0.00      0.00        32\n",
            "         134       0.50      0.09      0.15        35\n",
            "         135       0.00      0.00      0.00        37\n",
            "         136       0.00      0.00      0.00        55\n",
            "         137       0.38      0.24      0.30        41\n",
            "         138       0.00      0.00      0.00        15\n",
            "         139       0.33      0.03      0.06        99\n",
            "         140       0.00      0.00      0.00        86\n",
            "         141       0.57      0.08      0.13        53\n",
            "         142       0.25      0.03      0.05        36\n",
            "         143       0.00      0.00      0.00        66\n",
            "         144       1.00      0.02      0.03        64\n",
            "         145       0.00      0.00      0.00        25\n",
            "         146       0.33      0.02      0.03       125\n",
            "         147       0.33      0.27      0.30        15\n",
            "         148       0.00      0.00      0.00        48\n",
            "         149       0.41      0.17      0.24        65\n",
            "         150       1.00      0.09      0.17        11\n",
            "         151       0.00      0.00      0.00        15\n",
            "         152       0.50      0.15      0.24        52\n",
            "         153       0.50      0.17      0.25        18\n",
            "         154       0.00      0.00      0.00        16\n",
            "         155       0.00      0.00      0.00        20\n",
            "         156       0.55      0.10      0.17       121\n",
            "         157       0.00      0.00      0.00       107\n",
            "         158       0.00      0.00      0.00        15\n",
            "         159       0.00      0.00      0.00       105\n",
            "         160       0.00      0.00      0.00        69\n",
            "         161       0.71      0.18      0.29        56\n",
            "         162       0.00      0.00      0.00        47\n",
            "         163       0.00      0.00      0.00       121\n",
            "         164       0.46      0.15      0.22        41\n",
            "         165       0.00      0.00      0.00       229\n",
            "         166       0.00      0.00      0.00        98\n",
            "         167       0.00      0.00      0.00        33\n",
            "         168       0.67      0.09      0.16        44\n",
            "         169       0.00      0.00      0.00        45\n",
            "         170       0.00      0.00      0.00        51\n",
            "         171       0.00      0.00      0.00        18\n",
            "         172       0.70      0.33      0.45        48\n",
            "         173       0.00      0.00      0.00        12\n",
            "         174       0.43      0.05      0.09        62\n",
            "         175       0.00      0.00      0.00        44\n",
            "         176       0.56      0.30      0.39        30\n",
            "         177       0.00      0.00      0.00        30\n",
            "         178       0.00      0.00      0.00         0\n",
            "         179       0.00      0.00      0.00         1\n",
            "         180       1.00      0.03      0.05        40\n",
            "         181       0.33      0.05      0.08        44\n",
            "         182       0.00      0.00      0.00         2\n",
            "         183       0.00      0.00      0.00        75\n",
            "         184       0.00      0.00      0.00         4\n",
            "         185       0.69      0.17      0.28        64\n",
            "         186       0.00      0.00      0.00        12\n",
            "         187       0.00      0.00      0.00        55\n",
            "         188       0.00      0.00      0.00        64\n",
            "         189       0.00      0.00      0.00        96\n",
            "         190       0.00      0.00      0.00        22\n",
            "         191       0.00      0.00      0.00        76\n",
            "         192       0.00      0.00      0.00        45\n",
            "         193       0.75      0.21      0.33        14\n",
            "         194       0.00      0.00      0.00        50\n",
            "         195       0.00      0.00      0.00        20\n",
            "         196       0.00      0.00      0.00        35\n",
            "         197       0.75      0.13      0.22        94\n",
            "         198       0.00      0.00      0.00        14\n",
            "         199       0.00      0.00      0.00        25\n",
            "         200       0.00      0.00      0.00        54\n",
            "         201       0.00      0.00      0.00        22\n",
            "         202       0.00      0.00      0.00        43\n",
            "         203       0.00      0.00      0.00        43\n",
            "         204       0.91      0.16      0.27        62\n",
            "         205       0.00      0.00      0.00         3\n",
            "         206       0.33      0.02      0.04        43\n",
            "         207       0.00      0.00      0.00         7\n",
            "         208       0.50      0.12      0.20         8\n",
            "         209       0.00      0.00      0.00        42\n",
            "         210       0.00      0.00      0.00        10\n",
            "         211       0.00      0.00      0.00        40\n",
            "         212       0.00      0.00      0.00        23\n",
            "         213       0.00      0.00      0.00         6\n",
            "         214       1.00      0.02      0.04        47\n",
            "         215       0.00      0.00      0.00        62\n",
            "         216       0.00      0.00      0.00        77\n",
            "         217       0.00      0.00      0.00        22\n",
            "         218       0.00      0.00      0.00         3\n",
            "         219       0.00      0.00      0.00        28\n",
            "         220       0.00      0.00      0.00        81\n",
            "         221       1.00      0.03      0.06        31\n",
            "         222       0.50      0.03      0.06        34\n",
            "         223       0.00      0.00      0.00        60\n",
            "         224       0.00      0.00      0.00        10\n",
            "         225       0.00      0.00      0.00        10\n",
            "         226       0.00      0.00      0.00        92\n",
            "         227       0.00      0.00      0.00        13\n",
            "         228       0.00      0.00      0.00        13\n",
            "         229       0.00      0.00      0.00        43\n",
            "         230       0.43      0.09      0.14        35\n",
            "         231       0.00      0.00      0.00         4\n",
            "         232       0.00      0.00      0.00        20\n",
            "         233       0.00      0.00      0.00       145\n",
            "         234       0.00      0.00      0.00        55\n",
            "         235       0.00      0.00      0.00         2\n",
            "         236       0.75      0.08      0.15        37\n",
            "         237       0.00      0.00      0.00        90\n",
            "         238       0.00      0.00      0.00        58\n",
            "         239       0.00      0.00      0.00        20\n",
            "         240       0.00      0.00      0.00        61\n",
            "         241       0.00      0.00      0.00        42\n",
            "         242       0.00      0.00      0.00        30\n",
            "         243       0.00      0.00      0.00        66\n",
            "         244       0.00      0.00      0.00        42\n",
            "         245       0.00      0.00      0.00        31\n",
            "         246       0.25      0.17      0.20         6\n",
            "         247       0.00      0.00      0.00        18\n",
            "         248       0.00      0.00      0.00        51\n",
            "         249       0.00      0.00      0.00        17\n",
            "         250       0.00      0.00      0.00        22\n",
            "         251       0.00      0.00      0.00        52\n",
            "         252       0.17      0.03      0.06        29\n",
            "         253       0.00      0.00      0.00        28\n",
            "         254       0.00      0.00      0.00        10\n",
            "         255       0.00      0.00      0.00         5\n",
            "         256       0.00      0.00      0.00         3\n",
            "         257       0.00      0.00      0.00        41\n",
            "         258       0.00      0.00      0.00        30\n",
            "         259       0.00      0.00      0.00         3\n",
            "         260       0.00      0.00      0.00        38\n",
            "         261       0.00      0.00      0.00         1\n",
            "         262       0.00      0.00      0.00        19\n",
            "         263       0.00      0.00      0.00        14\n",
            "         264       0.00      0.00      0.00        37\n",
            "         265       0.00      0.00      0.00         9\n",
            "         266       0.36      0.09      0.14        45\n",
            "         267       0.53      0.27      0.36        33\n",
            "         268       0.00      0.00      0.00        16\n",
            "         269       0.00      0.00      0.00        35\n",
            "         270       0.00      0.00      0.00        11\n",
            "         271       0.00      0.00      0.00        30\n",
            "         272       0.50      0.25      0.33         8\n",
            "         273       0.00      0.00      0.00        21\n",
            "         274       0.00      0.00      0.00       123\n",
            "         275       0.00      0.00      0.00        67\n",
            "         276       0.00      0.00      0.00        20\n",
            "         277       0.00      0.00      0.00        14\n",
            "         278       0.00      0.00      0.00        19\n",
            "         279       0.00      0.00      0.00        12\n",
            "         280       0.00      0.00      0.00        15\n",
            "         281       0.00      0.00      0.00        17\n",
            "         282       0.00      0.00      0.00        41\n",
            "         283       0.00      0.00      0.00        15\n",
            "         284       0.00      0.00      0.00        74\n",
            "         285       0.00      0.00      0.00        38\n",
            "         286       0.00      0.00      0.00        16\n",
            "         287       0.00      0.00      0.00        30\n",
            "         288       0.00      0.00      0.00        28\n",
            "         289       0.00      0.00      0.00        21\n",
            "         290       0.00      0.00      0.00        41\n",
            "         291       0.00      0.00      0.00        12\n",
            "         292       0.00      0.00      0.00        24\n",
            "         293       0.56      0.25      0.34        20\n",
            "         294       0.00      0.00      0.00        23\n",
            "         295       0.00      0.00      0.00        29\n",
            "         296       0.00      0.00      0.00        28\n",
            "         297       0.00      0.00      0.00        42\n",
            "         298       0.00      0.00      0.00        53\n",
            "         299       0.00      0.00      0.00        36\n",
            "         300       0.00      0.00      0.00        41\n",
            "         301       0.00      0.00      0.00        37\n",
            "         302       0.00      0.00      0.00        26\n",
            "         303       0.50      0.09      0.15        11\n",
            "         304       0.00      0.00      0.00        31\n",
            "         305       0.00      0.00      0.00        17\n",
            "         306       0.00      0.00      0.00         9\n",
            "         307       0.00      0.00      0.00         6\n",
            "         308       0.00      0.00      0.00        34\n",
            "         309       0.67      0.19      0.29        43\n",
            "         310       0.00      0.00      0.00        30\n",
            "         311       0.67      0.04      0.08        50\n",
            "         312       0.00      0.00      0.00        24\n",
            "         313       0.00      0.00      0.00        42\n",
            "         314       0.00      0.00      0.00        22\n",
            "         315       0.00      0.00      0.00        58\n",
            "         316       0.00      0.00      0.00        10\n",
            "         317       0.50      0.16      0.24        57\n",
            "         318       0.00      0.00      0.00        10\n",
            "         319       0.00      0.00      0.00        11\n",
            "         320       1.00      0.09      0.17        11\n",
            "         321       0.00      0.00      0.00         8\n",
            "         322       0.00      0.00      0.00        22\n",
            "         323       0.00      0.00      0.00        28\n",
            "         324       0.00      0.00      0.00        50\n",
            "         325       1.00      0.06      0.11        18\n",
            "         326       0.00      0.00      0.00        33\n",
            "         327       0.67      0.12      0.20        17\n",
            "         328       0.00      0.00      0.00        29\n",
            "         329       0.00      0.00      0.00         7\n",
            "         330       0.00      0.00      0.00        10\n",
            "         331       0.00      0.00      0.00        25\n",
            "         332       0.00      0.00      0.00         2\n",
            "         333       0.25      0.09      0.13        11\n",
            "         334       0.00      0.00      0.00        24\n",
            "         335       0.00      0.00      0.00         5\n",
            "         336       0.00      0.00      0.00        33\n",
            "         337       0.00      0.00      0.00        30\n",
            "         338       0.00      0.00      0.00        42\n",
            "         339       0.00      0.00      0.00        26\n",
            "         340       0.00      0.00      0.00        36\n",
            "         341       0.00      0.00      0.00        13\n",
            "         342       0.00      0.00      0.00        11\n",
            "         343       0.00      0.00      0.00        10\n",
            "         344       0.57      0.19      0.29        21\n",
            "         345       0.00      0.00      0.00         0\n",
            "         346       0.00      0.00      0.00         6\n",
            "         347       0.00      0.00      0.00        12\n",
            "         348       0.00      0.00      0.00        13\n",
            "         349       0.00      0.00      0.00        24\n",
            "         350       0.00      0.00      0.00        27\n",
            "         351       0.50      0.12      0.19        43\n",
            "         352       0.00      0.00      0.00        30\n",
            "         353       0.00      0.00      0.00        22\n",
            "         354       0.00      0.00      0.00        31\n",
            "         355       0.00      0.00      0.00        10\n",
            "         356       1.00      0.05      0.10        20\n",
            "         357       0.00      0.00      0.00        20\n",
            "         358       0.00      0.00      0.00        28\n",
            "         359       1.00      0.05      0.09        21\n",
            "         360       0.00      0.00      0.00        25\n",
            "         361       0.00      0.00      0.00        35\n",
            "         362       0.00      0.00      0.00        36\n",
            "         363       0.00      0.00      0.00        17\n",
            "         364       0.00      0.00      0.00        13\n",
            "         365       0.00      0.00      0.00        21\n",
            "         366       0.00      0.00      0.00        18\n",
            "         367       0.00      0.00      0.00        97\n",
            "         368       0.00      0.00      0.00        29\n",
            "         369       0.00      0.00      0.00        12\n",
            "         370       0.00      0.00      0.00        13\n",
            "         371       0.00      0.00      0.00        18\n",
            "         372       0.00      0.00      0.00         6\n",
            "         373       0.00      0.00      0.00         6\n",
            "         374       0.00      0.00      0.00        30\n",
            "         375       0.40      0.07      0.12        27\n",
            "         376       0.00      0.00      0.00        28\n",
            "         377       0.00      0.00      0.00         2\n",
            "         378       0.00      0.00      0.00         4\n",
            "         379       0.00      0.00      0.00        19\n",
            "         380       0.00      0.00      0.00         5\n",
            "         381       0.00      0.00      0.00        18\n",
            "         382       0.00      0.00      0.00        22\n",
            "         383       0.00      0.00      0.00        16\n",
            "         384       0.50      0.23      0.32        13\n",
            "         385       0.33      0.06      0.10        18\n",
            "         386       0.00      0.00      0.00        11\n",
            "         387       0.00      0.00      0.00        88\n",
            "         388       0.00      0.00      0.00        13\n",
            "         389       0.00      0.00      0.00         6\n",
            "         390       0.00      0.00      0.00         6\n",
            "         391       0.00      0.00      0.00        51\n",
            "         392       0.00      0.00      0.00        13\n",
            "         393       0.00      0.00      0.00        37\n",
            "         394       0.00      0.00      0.00         6\n",
            "         395       0.00      0.00      0.00         9\n",
            "         396       0.00      0.00      0.00        13\n",
            "         397       0.00      0.00      0.00         6\n",
            "         398       0.00      0.00      0.00        29\n",
            "         399       0.00      0.00      0.00        33\n",
            "         400       0.00      0.00      0.00        31\n",
            "         401       0.00      0.00      0.00        50\n",
            "         402       0.00      0.00      0.00        18\n",
            "         403       0.00      0.00      0.00         7\n",
            "         404       0.00      0.00      0.00        26\n",
            "         405       0.00      0.00      0.00        56\n",
            "         406       0.00      0.00      0.00         4\n",
            "         407       0.00      0.00      0.00        17\n",
            "         408       0.00      0.00      0.00        11\n",
            "         409       0.00      0.00      0.00        18\n",
            "         410       0.00      0.00      0.00        10\n",
            "         411       0.00      0.00      0.00        45\n",
            "         412       0.00      0.00      0.00        20\n",
            "         413       0.00      0.00      0.00        25\n",
            "         414       0.00      0.00      0.00        20\n",
            "         415       0.00      0.00      0.00         6\n",
            "         416       0.00      0.00      0.00        26\n",
            "         417       0.00      0.00      0.00        10\n",
            "         418       0.00      0.00      0.00        18\n",
            "         419       0.00      0.00      0.00         6\n",
            "         420       1.00      0.06      0.11        17\n",
            "         421       0.00      0.00      0.00         1\n",
            "         422       0.00      0.00      0.00         6\n",
            "         423       0.00      0.00      0.00        12\n",
            "         424       0.00      0.00      0.00         4\n",
            "         425       0.00      0.00      0.00        11\n",
            "         426       0.00      0.00      0.00        11\n",
            "         427       0.00      0.00      0.00         8\n",
            "         428       0.00      0.00      0.00        26\n",
            "         429       0.00      0.00      0.00        40\n",
            "         430       0.00      0.00      0.00         2\n",
            "         431       0.00      0.00      0.00        35\n",
            "         432       0.00      0.00      0.00        15\n",
            "         433       0.00      0.00      0.00        18\n",
            "         434       0.00      0.00      0.00         0\n",
            "         435       0.00      0.00      0.00         0\n",
            "         436       0.00      0.00      0.00        28\n",
            "         437       0.00      0.00      0.00        33\n",
            "         438       0.00      0.00      0.00        20\n",
            "         439       0.00      0.00      0.00        36\n",
            "         440       0.00      0.00      0.00        18\n",
            "         441       0.00      0.00      0.00        18\n",
            "         442       0.00      0.00      0.00        16\n",
            "         443       0.00      0.00      0.00        22\n",
            "         444       0.00      0.00      0.00         6\n",
            "         445       0.00      0.00      0.00        21\n",
            "         446       0.00      0.00      0.00        46\n",
            "         447       0.00      0.00      0.00        69\n",
            "         448       0.00      0.00      0.00         7\n",
            "         449       0.00      0.00      0.00         3\n",
            "         450       0.00      0.00      0.00        52\n",
            "         451       0.00      0.00      0.00        16\n",
            "         452       0.00      0.00      0.00        17\n",
            "         453       0.00      0.00      0.00        13\n",
            "         454       0.00      0.00      0.00        11\n",
            "         455       0.00      0.00      0.00        12\n",
            "         456       0.00      0.00      0.00         6\n",
            "         457       0.00      0.00      0.00        18\n",
            "         458       0.00      0.00      0.00        15\n",
            "         459       0.00      0.00      0.00        28\n",
            "         460       0.00      0.00      0.00        18\n",
            "         461       0.00      0.00      0.00        10\n",
            "         462       0.00      0.00      0.00        24\n",
            "         463       0.00      0.00      0.00        18\n",
            "         464       0.00      0.00      0.00        39\n",
            "         465       0.00      0.00      0.00        11\n",
            "         466       0.00      0.00      0.00        35\n",
            "         467       0.00      0.00      0.00        21\n",
            "         468       0.00      0.00      0.00        37\n",
            "         469       0.00      0.00      0.00         5\n",
            "         470       1.00      0.12      0.22         8\n",
            "         471       0.00      0.00      0.00        37\n",
            "         472       0.00      0.00      0.00        47\n",
            "         473       0.00      0.00      0.00        14\n",
            "         474       0.00      0.00      0.00        23\n",
            "         475       0.00      0.00      0.00        66\n",
            "         476       0.00      0.00      0.00         3\n",
            "         477       0.00      0.00      0.00        19\n",
            "         478       0.00      0.00      0.00         1\n",
            "         479       0.00      0.00      0.00        23\n",
            "         480       0.00      0.00      0.00        60\n",
            "         481       0.00      0.00      0.00        26\n",
            "         482       0.00      0.00      0.00         4\n",
            "         483       0.00      0.00      0.00         8\n",
            "         484       0.00      0.00      0.00        23\n",
            "         485       0.00      0.00      0.00        18\n",
            "         486       0.00      0.00      0.00        12\n",
            "         487       0.00      0.00      0.00        29\n",
            "         488       0.00      0.00      0.00         1\n",
            "         489       0.00      0.00      0.00         6\n",
            "         490       0.00      0.00      0.00         7\n",
            "         491       0.00      0.00      0.00         3\n",
            "         492       0.00      0.00      0.00        10\n",
            "         493       0.00      0.00      0.00        19\n",
            "         494       0.00      0.00      0.00         7\n",
            "         495       0.00      0.00      0.00         8\n",
            "         496       0.00      0.00      0.00        18\n",
            "         497       0.00      0.00      0.00        72\n",
            "         498       0.00      0.00      0.00         8\n",
            "         499       0.00      0.00      0.00        32\n",
            "\n",
            "   micro avg       0.74      0.16      0.26     37472\n",
            "   macro avg       0.20      0.05      0.07     37472\n",
            "weighted avg       0.49      0.16      0.22     37472\n",
            " samples avg       0.25      0.16      0.18     37472\n",
            "\n",
            "Time taken to run this cell : 0:03:41.090821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VNFZocCC7Tx9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}